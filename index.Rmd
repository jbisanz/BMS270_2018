---
title: "BMS 270/BMI 219 The Human Microbiome (2018)"
date: "May 15, 2018"
output: 
  html_document:
    fig_width: 11
    fig_height: 8.5
---

```{r, include=F}
knitr::opts_chunk$set(echo = TRUE, message=TRUE, warning=FALSE,  cache=FALSE, tidy=TRUE)
```
# Computational Methods for Exploring the Microbiome
***

The following tutorial focuses on a subset of data derived from: [The microbiota at multiple body sites during pregnancy in a rural Tanzanian population and the effects of Moringa supplemented probiotic yogurt doi:10.1128/AEM.00780-15](http://aem.asm.org/content/early/2015/05/13/AEM.00780-15.abstract). The study was comprised of a longitudinal analysis of 56 pregnant women. We will revisit the finding that there is a major shift in the vaginal microbiome at birth using a completely independent set of tools from those in the paper using a workflow entirely carried out in R. We will focus on a subset of 20 women for the purposes of this analysis comparing enrollment in the second trimester, to birth. We are using the vaginal microbiome data set here as it has relatively lower diversity compared to the gut and in previous analysis showed very clear shifts in composition.


The tutorial will require some basic knowledge of the R language. At this point in time having some basic skills in bash, R, python, matlab, and/or some combination thereof is required in the microbiome field. All languages use more or less the same basic logic (for biological computing anyway) but differ in their syntax. It is more important to know what you want to do, than how to do it. Do not hesitate to ask for help if you are having trouble. Also check [here](https://www.rstudio.com/resources/cheatsheets/) for helpful cheat sheets. The commands you will need are all supplied in gray boxes with the output below.
<br>

If you are not familiar with R, please watch these videos:

*  [Introduction to R Programming with DataCamp](https://www.youtube.com/watch?v=HkNFn6eosaU)
*  [Getting started with R and RStudio](https://www.youtube.com/watch?v=lVKMsaWju8w&t=3s)
*  If you are interested in learning more R, I recommend [this book](https://www.amazon.com/Learning-Step-Step-Function-Analysis/dp/1449357105).

***

# Installing necessary requirements {#Installation}

***

## This entire process could take ~10-15 minutes, please ensure this has been done before coming to class!

If you do not already have R, download the correct version for your operating system [here](https://cran.cnr.berkeley.edu/). Then download the newest version of R studio for your operating system [here](https://www.rstudio.com/products/rstudio/download2/). Please ensure your version of R is at least 3.4.2 . You can check this with the following command:

```{r}
print(R.Version()$version.string)
```

<<<<<<< Updated upstream
<b>If you are a mac user who has never used any form of bioinformatic tool or programming language on your computer, it may be a good idea to download the Xcode Developer tools from the Apple app store</b>
=======
<b>If you are a mac user who has never used any form of bioinformatic tool or programming language on your computer, it may be a good idea to download the Xcode Developer tools from the Apple app store if you do not already have it.</b>
>>>>>>> Stashed changes

Open R studio and click File > New File > R script. Save this file in a folder of your choice as <i>YourName.MicrobiomeTutorial.R</i>.

Next, click Session > Set Working Directory > Choose Directory. Select the folder in which you placed your .R file.

### For Ubuntu users only:

```{r, eval=F}
###For Ubuntu users only, you may need to do the following:
sudo apt-get install libcurl4-gnutls-dev #in terminal
sudo apt-get install curl #in terminal
sudo apt-get install gsl-bin libgs10-dev #in terminal
install.packages("RCurl") #in R
```

Next run the following code which will download all required packages for this tutorial if you do not already have them. It will also download the raw data from European Nucleotide Archive. <b>If asked to compile, reply yes</b>, this may happen multiple times. On OSX you may be asked to install developer tools to which you should accept. <b>If asked to update other packages, type n for none</b>. You may have to do this multiple times. <i>For advanced users, this script may update versions of packages you already have. Feel free to manually install or update as needed based on the source code of the install script.</i>

```{r, eval=F}
source("https://raw.githubusercontent.com/jbisanz/BMS270_2018/master/InstallTutorial.R")
```

In OSX and Ubuntu ensure that the folders RawData and RDS (downloaded by the above script) are in the same directory as <i>YourName.MicrobiomeTutorial.R</i>. <b>If you are running windows, the sequencing data was not automatically downloaded. Please manually download from this [link](https://github.com/jbisanz/BMS270_BMI219/raw/master/tutorialdata.zip), and decompress in the same directory as <i>YourName.MicrobiomeTutorial.R</i></b>

***

# Load packages

To ensure that you have successfully installed all packages, run the following commands one by one paying attention to the output. Warning messages about object masking are to be expected in this case but OK.

```{r, message=F, warning=F}
require(vegan) #Diversity functions for microbiome data
require(dada2) #Our denoising and primary sequence processing tool
require(phyloseq) #plotting and analysis tools for microbiome data
require(MicrobeR) #plotting and functions for microbiome data
require(DESeq2) #differential expression/feature abundance tool
require(tidyverse) #a whole gang of packages and functions for data wrangling and graphing
require(DECIPHER) #for nucleotide alignments
require(phangorn) #phylogenetic tree tools
```

If any of these fail to load, try re-sourcing the InstallTutorial.R script above. It will only download the data once. If you still are unable to install any of the packages, please [email me](mailto:jordan.bisanz@ucsf.edu).

It is often quite handy to store intermediate files if R crashes, or for tracking of analyses. We will create a directory for this called RDS. We will store intermediate files in RDS format which allows them to be written and reloaded into R quickly and with minimal hard drive usage.

```{r}
dir.create("RDS")
```

Finally, it is a good idea to be aware of your environment and what versions of packages you have installed. You can do this with the following command. Your environment will not look exactly like mine, but this is a good thing to keep track of for when it comes to try to repeat analyses or publish your data.

```{r}
print(sessionInfo())
```

***

## You are now ready for the tutorial! Wait for class before moving on!

***

<<<<<<< Updated upstream
=======
# 2. Metadata Import {#Metadata}

***

## Background:

The key to a good study starts before the sequencing even begins. Metadata refers to the a list of your sample names and what they actually are. In its simplest form, it could simply be disease X versus healthy control. In an ideal world, it is full of as many relevant covariates as possible. Before starting the DNA extractions, I highly recommend putting together the metadata to ensure you have sufficient information for meaningful analysis. Here we have provided a text file called "Tutorial_metadata.txt" which is in tab separated variable format (TSV). These files can be opened and edited in excel or Google sheets, and along with comma separated variable format (CSV), are among most common ways to store metadata. To get you started, try applying the following code to import and view the associated metadata:

```{r}
metadata<-read.table("Tutorial_metadata.txt",
                     sep ='\t', # our table is a TSV file with tabs between every column
                     header = TRUE, #the first row of our metadata contains the variable names
                     stringsAsFactors = FALSE #This has to do with how R treats text, for now it will be easiest to not treat text as a factor
                     )
Nice.Table(metadata)
```

Finally, we will do some minor formatting to our data. We will give the rows of our metadata table the sample_name variable. While not strictly necessary, some tools expect this, including Phyloseq and MicrobeR. Also, we will explicitly order some variables in our metadata putting the second trimester visit before Birth and ordering the Nugent score from healthy -> not healthy.

```{r}
rownames(metadata)<-metadata$sample_name
metadata$Timepoint<-factor(metadata$Timepoint, levels=c("SecondTrimester","Birth")) #This puts the classes in order for future analyses and plots
metadata$anonymized_name<-factor(metadata$anonymized_name) #make the participant name a categorical variable
metadata$nugent_class<-factor(metadata$nugent_class, levels=c("healthy","intermediate","bv")) #make nugent class a categorical variable ordered from healthy -> bacterial vaginosis

saveRDS(metadata, "RDS/metadata.RDS") #save a copy for later
```

## Variable Explanations:
  + sample_name : The unique identifier of the sample. This corresponds to the name that will be generated in our feature table.
  + age : The age of the participant in years.
  + anonymized_name : A unique identifier of the participant in the study.
  + bmi : The body mass index (Kg/m^2^).
  + Timepoint : Time point in the study, IE either baseline (second trimester) or at birth.
  + weight_infant_1 : The delivery weight of the infant in Kg.
  + vaginal_ph : The pH of the microbial environment.
  + nugent_score : A clinical test based on manual interpretation of Gram-stain morphologies during microscopy.
  + nugent_class : A categorical variable derived from the Nugent score where low scores are healthy, and high scores are Bacterial Vaginosis. 
  + FTP : The FTP address which the files can be pulled from.

***

# 3. Sequencing Import and Processing {#dada2}

***

### Background:

  We can use R directly to download our files, although this can be done in many ways including manually. The code has been included here, however it was part of your install script so you should not need to download it again. In this case, the data is being pulled from the European Nucleotide Archive. If you wanted to reanalyze a published data set, say from [QIITA](https://qiita.ucsd.edu/), you could easily adopt this exact same code.

```{r, eval=F}
#Do not run again unless you did not download the raw data
dir.create("RawData") # A directory to store all of our data
for (i in 1:nrow(metadata)){
  if(!file.exists(paste0("RawData/", metadata[i,"sample_name"],".fastq.gz"))){
    download.file(metadata[i,"FTP"], paste0("RawData/", metadata[i,"sample_name"],".fastq.gz"), method="wget", quiet=F)
  } else {
    print(paste0("You have already downloaded: ", metadata[i,"sample_name"]))
  }
}
```

  There are many options for how to handle 16S rRNA gene sequencing. Conventionally clustering of sequences at a set threshold, usually 97%, is common. These are commonly called <b>OTUs</b> (Operational Taxonomic Units). It is now in vogue to use some form of denoising and avoid clustering all together. This has the advantage of providing the highest possible resolution. There is some debate about what these should be called, but for our purposes we will refer to them as <b>SVs</b> (Sequence Variants). Today we will use [DADA2](http://www.nature.com/nmeth/journal/v13/n7/full/nmeth.3869.html) denoising which can be accomplished completely in R. Similar approaches include Deblur (Knight Group) and UNOISE (Robert Edgar).

  To carry out these steps, I recommend inspecting the following dada2 tutorial:  [http://benjjneb.github.io/dada2/tutorial.html](http://benjjneb.github.io/dada2/tutorial.html). Many of the steps we will apply have been copied verbatim from this tutorial. <b>Note: We have single ended 1x150 sequencing so overlapping is not necessary and certain filtering steps only require the passing of one variable rather than two.</b>

  To help understand the denoising approach, you should look at the format of our raw data. Take a look at the first lines of a FASTQ file:

```{r}
readLines("RawData/2024.birth.MNIH02UP.BFF10F.V.fastq.gz", n=4) #read top 4 lines of file and print to screen
```

FASTQ files typically are a repeating pattern of 4 lines: 
* 1. The first starts with an @ sign followed by a unique identifier, in this case it denotes the sample of origin and some artifacts of the demultiplexing process.
* 2. The nucleotide sequence
* 3. A + sign denoting the end of the nucleotide sequence
* 4. The quality string. These characters actually denote a numeric code which give the probability that a sequencing error has occurred. In typical encoding, H would denote a score of 39 which has a 1:7700 probability of an error. A Q score of 10 denotes a 1:10 probability of an incorrect base call. It is imperative that the majority of your sequencing run has high quality scores, typically >30, but there is no fixed cutoff.

### Further Reading:

* [FASTQ files and quality scores](https://www.illumina.com/science/education/sequencing-quality-scores.html)
* [How Illumina Sequencers work](https://www.illumina.com/content/dam/illumina-marketing/documents/products/illumina_sequencing_introduction.pdf)
* [QIIME2](https://qiime2.org/)
* [QIIME](https://qiime.org/) - The conventional approach for 16S rRNA gene Sequencing
* [Mothur](mothur.org)

### Resources:
* [DADA2](http://www.nature.com/nmeth/journal/v13/n7/full/nmeth.3869.html)
* [DeBlur](http://msystems.asm.org/content/2/2/e00191-16)
* [UNOISE2](http://biorxiv.org/content/early/2016/10/15/081257)
* [dada2 Tutorial](http://benjjneb.github.io/dada2/tutorial.html) <i> Read here further for theoretical aspects.</i>

***

Start by examining the quality of a few random samples with x as cycle number and y as Quality score. What do you think of the quality?
```{r}
FASTQs<-paste0("RawData/", list.files("RawData")) # generate a list of file names
plotQualityProfile(FASTQs[c(1,10,20)]) #plot 3 arbitrarily selected samples
```
<i> Remember that sequencing quality almost always decreases as the number of cycles increases</i>.

<br><br>It would appear we have decent quality sequencing, although some samples show a sharp decline in quality in the late cycles and have lower quality in the early cycles. Try using the filterAndTrim command of dada2 as per the tutorial to filter your data. Try using these values if you think they are appropriate:

* truncQ=2, #truncate reads after a quality score of 2 or less
* truncLen=130, #truncate after 130 bases
* trimLeft=10, #remove 10 bases off the 5' end of the sequence
* maxN=0, #Don't allow any Ns in sequence
* maxEE=2, #A maximum number of expected errors
* rm.phix=TRUE, #Remove lingering PhiX (control DNA used in sequencing) as it is likely there is some.
* multithread=TRUE #Run parallel, if you can this will speed up filtering significantly. On some windows systems, this may not be possible.

<br><br>If you filter too aggressively you might not even end up the output of filterAndTrim as nothing will pass the filter. Make sure you have all your filtered files (check inside your FilteredData/ folder).
```{r}
dir.create("FilteredData") # Create a directory for filtered Read Data
filt.FASTQs<-paste0("FilteredData/", metadata$sample_name, "_filtered.fastq.gz") # Create a new names for filtered sequence data
filtered<-filterAndTrim(fwd=FASTQs, #The list of fastqs that we currently have
                        filt=filt.FASTQs, #The list of of new names for the filtered versions
                        compress=TRUE, #store the results as .gz to save on storage space
                        truncQ=2, #truncate reads after a quality score of 2 or less
                        truncLen=130, #truncate after 130 bases
                        trimLeft=10, #remove 10 bases off the 5' end of the sequence
                        maxN=0, #Don't allow any Ns in sequence
                        maxEE=2, #A maximum number of expected errors
                        rm.phix=TRUE, #Remove lingering PhiX... it is highly likely there is some
                        multithread=TRUE #Run parallel, if you can this will speed up filtering significantly ***On Windows you may need to set = FALSE if you recieve an error relating to mc.cores
                        )
```

It would be a good idea to look at how many reads were lost during filtering.
```{r}
print(paste("We removed a total of", sum(filtered[,1])-sum(filtered[,2]), "from", sum(filtered[,1]), "reads"))
```

This seems to be an acceptable loss. Now we need to do the most computationally intensive part of the process which is learning the error rates. I highly recommend enabling multithreading if possible.

```{r}
if(!file.exists("RDS/error_profile.RDS")){
  error_profile<-learnErrors(filt.FASTQs, multithread=TRUE)
  saveRDS(error_profile, "RDS/error_profile.RDS")
} else {
    print("Error profiles loaded from file")
    error_profile<-readRDS("RDS/error_profile.RDS")
}
```


This took ~ 3 minutes on both a 2017 2.8 GHz Intel Core i5 iMac and 2011 2.0 GHz Intel Core i7 Macbook Pro, each with 16Gb of RAM. The time to do this could very significantly depending on your computer. For this reason we have provided the error profile with the downloads for the tutorial. The code above checks if you already have the profile and loads it from disk when possible rather than recalculate.

Now dereplicate your sequences which will help speed things up later during denoising.

```{r}
derep<-derepFastq(filt.FASTQs, verbose=FALSE) #dereplicate sequences
names(derep) <- metadata$sample_name #name the dereplicated sequences by sample of origin
saveRDS(derep, "RDS/derep.RDS")
```

Now you can generate your denoised reads. Apply the `dada( )` function to denoise.

```{r}
denoised<-dada(derep, err=error_profile, multithread = TRUE) #denoise sequences, again on windows you may need to set multithread=FALSE
saveRDS(denoised, "RDS/denoised.RDS")
```

Finally make your table of sequence variants (SVs) and check the dimensions to ensure it seems plausible:
```{r}
sv.table<-makeSequenceTable(denoised) #make your feature table
print(paste("There are", ncol(sv.table),"SVs in", nrow(sv.table), "Samples"))
saveRDS(sv.table, "RDS/sv.table.RDS")
```


At this point, it would be wise to address sequence chimeras. For a discussion of chimeras, see [here](http://drive5.com/usearch/manual/chimera_formation.html). These erroneous sequences have no biological meaning and removing them helps reduce the number of features you will compare. There are many chimera removal algorithms, but today use the built in <i>removeBimeraDenovo( )</i> function and use method="pooled". Why do you think we would want to use the pooled method? After removing chimeras, check how many reads you removed.

```{r}
sv.table.nochim <- removeBimeraDenovo(sv.table, method="pooled", multithread=TRUE, verbose=TRUE) #remove chimeras, again you may need to specify multithread=FALSE on some windows systems
saveRDS(sv.table.nochim, "RDS/sv.table.nochim.RDS")
print(paste("After chimera removal, there are", ncol(sv.table.nochim),"SVs in", nrow(sv.table.nochim), "Samples"))
print(paste("Chimeric sequences represented", round(100*(1-sum(sv.table.nochim)/sum(sv.table)),2), "% of sequences"))
```
<b>Note: When doing PCR for 16S rRNA gene sequencing, don't use 35 cycles and use high fidelity enzymes.</b>

Now one last filtering step: remove SVs that are not present in at least 2 samples with at least 1 count! There are many ways you could apply this, but try filterfun(kOverA(2,1)) and the filter_taxa command from phyloseq or Confidence.Filter from MicrobeR. <i>Note: generally speaking, you should generate alpha diversity metrics before you apply any filtering, but for the purposes of reducing computational requirements, we are going to trim spurious features out now rather than later.</i>

```{r}
sv.table.filtered<-t(Confidence.Filter(t(sv.table.nochim), MINSAMPS=2, MINREADS = 1, VERBOSE=T)) #the t() function is to transpose the table, ie rotate it 90 degrees, depending on the function, certain orientations are required
saveRDS(sv.table.filtered, "RDS/sv.table.filtered.RDS")
```

Now we have a table of sequences and samples. But the sequences aren't particularly helpful to us. What we really want to know is what organisms those sequences belong to. There are multiple choices of database for this tool. For the purposes of today, we will use the [Ribosomal Database Project](https://rdp.cme.msu.edu/). Typically the [Green Genes](http://greengenes.secondgenome.com/downloads) or [SILVA](https://www.arb-silva.de/documentation/release-123/) databases are more commonly used but we are using the RDP database to save on computational time. I personally use SILVA. Use the <i>assignTaxonomy()</i> function of dada2 with the rdp_train_set_14.fa.gz that you downloaded as part of your installation.

```{r}
taxonomy <- as.data.frame(assignTaxonomy(sv.table.filtered, "rdp_train_set_14.fa.gz", multithread=TRUE, verbose=TRUE)) #assign taxonomy
```

To make visualizing the data easier, we can assign a unique ID to each of our sequence variants. I will create a new category in the taxonomy table called Seq that contains the SV sequence and  also a category for the unique ID.

```{r}
taxonomy$Seq<-rownames(taxonomy) #move the rownames (the actual sequence) to a column called seq
taxonomy$SV_ID<-paste0("SV_", seq(from=1, to=nrow(taxonomy), by=1)) # generate a new list of ids (SV_1,SV_2,...)
colnames(sv.table.filtered)<-taxonomy[colnames(sv.table.filtered),]$SV_ID #Our table of SVs currently has sequences for names, switch it to the unique ID you created above
rownames(taxonomy)<-taxonomy$SV_ID
saveRDS(taxonomy, "RDS/taxonomy.RDS")
```

<br> One last step before we do analysis. Generate a phylogenetic tree. We will use [this](https://f1000research.com/articles/5-1492/v2) workflow to carry it out completely in R. If you were on a unix computer with QIIME installed you could also use MicrobeR's Make.Tree command. The code below would generate a new tree, however this can take some time to run so instead we will use a precomputed tree which was downloaded as part of the tutorial data. Again, if it is missing, this code will regenerate it. This method of building a tree is extremely slow, and if you were dealing with >500 features, the [Fast Tree](http://www.microbesonline.org/fasttree/) algorithm would be supperior; however, it is not native to R.

```{r, message=F}
if(file.exists("RDS/tree.RDS")) {
    tree<-readRDS("RDS/tree.RDS")
} else{
seqs <- taxonomy$Seq
names(seqs) <- taxonomy$SV_ID # This propagates to the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA, verbose = FALSE)
phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phang.align)
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phang.align)
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", 
                    optInv=TRUE, 
                    optGamma=TRUE,
                    rearrangement = "stochastic",
                    control = pml.control(trace = 0))
tree<-fitGTR$tree
tree<-midpoint(tree) #midpoint root the tree
saveRDS(tree, "RDS/tree.RDS")
}
```

You have now completely generated the data we require to start meaningful analysis!!!

***

# 4. Exploratory Analysis {#plots}

***

### Background:

Before doing any statistical analysis, it is always a good idea to get a feel for your data. Bar plots and heat maps are a good approach for these. Phyloseq contains a number of tools for these analysis as does MicrobeR. In this next section, experiment with different plots to get a 1000-foot view of your data and an idea of what questions you might want to ask in more detailed analyses.

### Resources:

[Phyloseq Tutorials/Graphics](https://joey711.github.io/phyloseq/)

***

One thing to always be aware of when dealing with microbiome data (or many 'ome' data sets) is if your table is set up with sample names as rows and taxa as columns, or vice versa. Many tools explicitly expect one orientation versus the other. For going forward in this analysis, I would recommend transposing your table `t( )` to have your taxa as rows and samples as columns.

```{r}
sv.table.analysis<-t(sv.table.filtered) #transpose table
```

If you want to take advantage of phyloseq, it would be ideal to have a phyloseq object which has your feature table, taxonomic assignments, phylogenetic tree, and metadata all in one. Try creating one.

```{r, message=F}
phyobj<-phyloseq(otu_table(sv.table.analysis, taxa_are_rows = TRUE), tax_table(as.matrix(taxonomy)), phy_tree(tree), sample_data(metadata)) #make phyloseq object
```

Get a summary of this object:

```{r}
phyobj #look at summary
```

For plotting purposes it is often easier to look at higher level taxonomic assignments. Lets start by creating these.
<i>Hint: See this forum link: [https://github.com/joey711/phyloseq/issues/616](https://github.com/joey711/phyloseq/issues/616) or use the method from MicrobeR.</i>

```{r}
taxa.summaries<-Summarize.Taxa(sv.table.analysis, taxonomy) #Summarize 
```

Now try making a bar plot of Genus level Abundances using either Phyloseq or MicrobeR's <i>Microbiome.Barplot( )</i>.

```{r}
Microbiome.Barplot(taxa.summaries$Genus, metadata, CATEGORY = "Timepoint") + ggtitle("Genus Abundances by Time Point")
```

What do you notice about the composition of the microbiome at genus level comparing visit one and the birth time point? Are you starting to get an idea for follow up analyses?

Depending on the nature of the data, trends can sometimes be spotted in heat maps. Let's create one.

```{r}
Microbiome.Heatmap(sv.table.analysis, metadata, CATEGORY = "Timepoint", TRANSFORM="log10", NTOPFEATURES = 50)
```

Did this confirm what we saw above? What genus does SV_1 belong to? Try to figure this out <i>hint: look at your taxonomy table</i>.

***

# 5. Alpha Diversity {#alpha}

***

### Background:

Alpha diversity is a measure of diversity within samples. Perhaps the simplest metric you could think of is the number of species present in an ecosystem which is commonly applied. Others try to estimate both the species you can see, and the ones you can't, such as Chao1. Others are a little bit more complex such as Shannon Diversity which use both the number of species present and their abundances:
$$Div_{shannon} = - \sum_{i=1}^R p_i ln p_i$$
Where p is the proportional abundance of feature <i>i</i>.

### Further Reading:
* [List of diversity metrics and their meaning](https://forum.qiime2.org/t/alpha-and-beta-diversity-explanations-and-commands/2282)
* [Comparison of alpha diversty metrics](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3775626/)
* [Studying Microbial Diversity](http://readiab.org/book/latest/3/1.html)

***

Lets start by using two commonly applied measures of alpha diversity: Observed Species and Shannon Diversity. You could either use vegan's <i>diversity( )</i> or phyloseq's <i>plot_richness( )</i>.

```{r}
print(plot_richness(phyobj, x="Timepoint", color="anonymized_name", measures=c("Observed","Shannon")) + theme_bw()) 
```
<b>Note:</b> You may get an error here about a lack of singleton reads. This is a result of our earlier filtering and does not represent a problem for your data set.

While this figure helps show that alpha diversity is altered, it is difficult to see how it changes on a per individual basis. Since Phyloseq creates this figure using a package called ggplot2, it is possible to add in connecting lines directly using metadata already part of the plot.

```{r}
print(plot_richness(phyobj, x="Timepoint", color="anonymized_name", measures=c("Observed","Shannon")) 
      + geom_line(aes(group=anonymized_name)) # add lines connected by individual
      + theme_bw() #I perfer a white rather than gray background
      + theme(legend.position="none") #we do not need the legend, but feel free to include
)
```

It certainly appears that we have a trend. It would be ideal to test this statistically. Generally speaking, in a 2-way comparison, a t-test or Mann-Whitney U test are appropriate. The data does not appear to be highly skewed so it should be safe to carry out a t-test. Since the data represents repeated sampling of the same individuals, you should ensure this is also a paired analysis. Both t-tests <i>(t.test)</i> and Mann-Whitney U <i>(wilcox.test)</i> are built into R. This next section is using the pipe operator `%>%` which passes the output of a function to the subsequent line. This is common in shell scripting but less common in R. It avoids the storing of intermediates. Test the effect on Observed SVs:

```{r}
Sobs<-data.frame(Sobs=vegan::specnumber(sv.table.analysis, MARGIN=2)) %>% # generate the species richness, margin specifies that our samples are the columns of our table
  rownames_to_column("sample_name") %>% #move the rownames to a column called sample_name for merger with our metdata
  left_join(metadata) %>% #join it with the matching metadata so we know the participant and the time point
  reshape2::dcast(anonymized_name~Timepoint, value.var="Sobs") #lets make a modified version of the table where the participant is the on the rows, and the columns are the Sobs at baseline and birth

Nice.Table(Sobs)

t.test(Sobs$Birth, Sobs$SecondTrimester, paired=T)
```

Based on the above result, there is an average of 17 more observed SVs at birth comparied to the second trimester time point.

<i>*Depending on your alpha diversity metric of choice, you may or may not wish to subsample (normalize for sequencing effort) your data before the calculation. We will skip doing it today but you will subsample for later analysis.</i>

### Conclusions:

What has this told us about the composition and diversity of the microbiome comparing early pregnancy and birth?

***

# 6. Beta Diversity{#beta}

***

### Background:

Beta diversity refers to between sample similarity and is a commonly used way to compare communities as a whole. There are many metrics commonly applied. The most commonly encountered will be [UniFrac](https://en.wikipedia.org/wiki/UniFrac) and/or [Bray Curtis](https://en.wikipedia.org/wiki/Bray%E2%80%93Curtis_dissimilarity). At their simplest level, they are looking at the overlap between two communities and generating a value of dissimilarity. Typically a value of 0 denotes identical community composition while 1 suggests non-overlapping communities. The key lies in how they are calculated. One large difference is that UniFrac applies a phylogenetic tree to normalize these values for the evolutionary distance between community members while Bray Curtis does not. An example of this is that to Bray Curtis, <i>Lactobacillus crispatus</i> and <i>Lactobacillus iners</i> are just as different as <i>Lactobacillus crispatus</i> and <i>E. coli</i>. Because <i>L. crispatus</i> and <i>L. iners</i> belong to the same genus, this is a much smaller difference to a UniFrac Metric. One last difference, unweighted UniFrac only uses the presence/absence of features, while weighted Unifrac also uses their abundances. As such unweighted UniFrac (and similar non-abundance weighted metrics) are prone to the effects of very low abundance taxa which may be variable based on sampling depth. For this reason it is usually advisable to subsample or rarefy data. This is a way to normalize for sequencing depth <i>in silico</i> which is appropriate here, but [may not always be advisable](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003531). 

Many people confuse the idea of beta diversity metrics and ordination/principal components/coordinates analysis (NDMS/PCA/PCoA). Beta diversity creates sets of pair-wise difference metrics while ordination approaches reduce the dimensionality of the data to one that we can visualize.

## Further Reading:

* [Studying Microbial Diversity](http://readiab.org/book/latest/3/1.html)
* [List of diversity metrics and their meaning](https://forum.qiime2.org/t/alpha-and-beta-diversity-explanations-and-commands/2282)

## Resources:

* [https://joey711.github.io/phyloseq/plot_ordination-examples.html](https://joey711.github.io/phyloseq/plot_ordination-examples.html)
* [http://cc.oulu.fi/~jarioksa/softhelp/vegan/html/adonis.html](http://cc.oulu.fi/~jarioksa/softhelp/vegan/html/adonis.html)

***

To start, generate principal coordinate analyses of Bray Curtis, Weighted UniFrac, and Unweighted UniFrac. This can be accomplished using Phyloseq's `plot_ordination()` or MicrobeR's `PCoA()`. `plot_ordination` has many more options for both distance metrics and ordination techniques so feel free to play around with them.

```{r, message=F}
PCoA("braycurtis", metadata, sv.table.analysis, COLOR="Timepoint", TREE=tree, ADONIS = F)
PCoA("weightedunifrac", metadata, sv.table.analysis, COLOR="Timepoint", TREE=tree, ADONIS = F)
PCoA("unweightedunifrac", metadata, sv.table.analysis, COLOR="Timepoint", TREE=tree, ADONIS = F)
```

What do you note about how each of the approaches pictured the data? Which one looks best to you? An additional technical note, ideally you want as much variation explained on the graph as possible which is usually plotted in the axes labels. Pick the metric that you think best represents the data and move forward with that. I am going to select weighted UniFrac. Some times meaningful information is contained on an additional axis of the PCoA. While not necessary, try rendering this in 3D using MicrobeR's PCoA3D! <i>If you do not see this rendering, enable webgl in your browser. In chrome, type [chrome://flags](chrome://flags) in your address bar, then enable WebGL2.0. This may not work on some windows systems.</i>

```{r, message=F}
PCoA3D("weightedunifrac", metadata, sv.table.analysis, COLOR="Timepoint", TREE=tree) #This may not work on some windows system
```

Did this help at all?

You have established visually that there appears to be differences in community structure between pregnancy and Birth. Remember that this is longitudinal sampling. To help look at sample pairing, connect points belonging to the same person using a similar approach to the one you used in the alpha diversity analysis.

```{r, message=F}
PCoA("weightedunifrac", metadata, sv.table.analysis, COLOR="Timepoint", TREE=tree, ADONIS = F) +
      geom_line(aes(group=anonymized_name), color="grey") + #Add a grey line connecting an individual's time points
      geom_text(aes(label=anonymized_name, color=Timepoint), hjust=0, vjust=1, size=3) + #add in the individual's name
      ggtitle("Weighted UniFrac: Points joined by Participant")

```

To test this statistically, two commonly applied tests are ANOSIM and ADONIS. Today we will apply ADONIS as it can handle both categorical and continuous variables while ANOSIM is limited to categorical variables. The general steps in this testing are to (1) generate your distance matrix (if you have not already), (2) carry out ADONIS test with vegan's `adonis( )` function. Look at both the effect of time, but also of the participant of origin.

#### 1- Generate the distance matrix

```{r, message=F}
sv.subsampled<-Subsample.Table(sv.table.analysis) #normalize for sequencing depth
unweighted<-UniFrac(phyloseq(otu_table(sv.subsampled, taxa_are_rows = T), tree), weighted=F)#Generate a distance matrix, consider taking a look at this
```

Let us look at the part of the table to get a feel for what the distance matrix looks like.

```{r}
Nice.Table(as.matrix(unweighted)[1:5,1:5])
```

####2- Now do test ADONIS test.

```{r}
adonis(unweighted ~ anonymized_name + Timepoint, data=metadata, permutations = 9999)
```

Were the results significant? An important number to also consider is the R^2^ value which indicates the % variation explained. What explains more of the variation, time or person? What would you have expected?

But again, remember this is a longitudinal analysis, so we can account for repeated time by indicating a strata. Repeat the test using a strata.

```{r}
adonis(unweighted~Timepoint, strata=metadata$anonymized_name, data=metadata) #include strata
```

Did this change your result?

### Conclusions:

What has this told us about the gross composition of the microbiome comparing early pregnancy and birth?

***

# 7. Testing for differential features with DESeq2 {#DESeq2}

***

### Background

Ultimately, what people often care most about is individual features/strains. After all, scientists tend to take a reductionist approach and want to identify novel pathogens or new probiotics in microbiome data. While fundamentally, 16S rRNA gene sequencing is a tool designed to look at communities as a whole, many approaches exist for looking at individual features. There are also a wide range of approaches and ethos for these. Generally speaking, it is a good idea to use multivariate statistics such as the beta diversity metrics above before looking for differences in individual taxa.


While there is not necessarily a single correct way to find significant taxa, there is certainly a wrong way: <b>Do not take raw sequence counts and do a series of uncorrected t-tests</b>. Remember that data is a technical sampling (if subsampled) of a technical sampling (which DNA binds to sequencing flow cell), of a technical sampling (which DNA was amplified by PCR primers), of a technical sampling (which portion of a sample was extracted for DNA), of a biological sampling (one arbitrary sample collection from an individual). As such it is important to realize that if you were to analyze replicate samples at every step of the process you would end up with slightly different numbers (but hopefully the same trends). Even the same sequencing library sequenced multiple times will yield slightly different results. Some tools are more false positive prone then others, and some create better visualization than others. Some links to tools are provided below but today we will use DESeq2. DESeq2 was originally intended for RNA-seq data, but this is conceptually no different than an amplicon library. Both are just a table of counts with similar technical considerations.

### Resources:
* [DESeq2](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8)
* [ALDEX2](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4030730/)
* [ANCOM](https://www.ncbi.nlm.nih.gov/pubmed/26028277)
* [LEFse](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3218848/)
* [PhyloSeq_to_DESeq2](https://www.bioconductor.org/packages/devel/bioc/vignettes/phyloseq/inst/doc/phyloseq-mixture-models.html)

***
We will use an approach based on these [instructions](https://www.bioconductor.org/packages/devel/bioc/vignettes/phyloseq/inst/doc/phyloseq-mixture-models.html).

```{r, eval=F}
#You can manually feed data to DESeq2 but today we are going to use the  phyloseq_to_deseq2() function of Phyloseq to do this.
dds = phyloseq_to_deseq2(phyobj, ~ Timepoint)
dds = DESeq(dds, test="Wald", fitType="local", parallel = TRUE)
```

Did this fail? It probably should have, and this is a fairly common problem. The problem is that there is a high probability that there will be microbes that are not present in every sample which causes problems in the normalization. 
<br><br>There are a number of ways we can work around this issue. Try the way addressed [here](https://github.com/joey711/phyloseq/issues/283) by supplying a new geometric mean function:

```{r}
dds = phyloseq_to_deseq2(phyobj, ~ Timepoint)
gm_mean = function(x, na.rm=TRUE){exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))} #declare new function
geoMeans = apply(counts(dds), 1, gm_mean) #calculate the geometric means
dds = estimateSizeFactors(dds, geoMeans = geoMeans) #manually calculate the size factor using these new geometric means instead of the default DESeq2 approach
dds = DESeq(dds, test="Wald", fitType="local")
```

Now that you have calculated your results, you can get the data back in tabular form and filter them for only those that have a FDR value<0.1 and a fold change of >2-fold. Remember that on a log2 scale, the actual fold change is 2^FoldChange^ so if we want a 2-fold change either up or down, 1/-1 is our actual cutoff.

```{r}
results.deseq<-as.data.frame(results(dds))
filt.results.deseq<-subset(results.deseq, padj<0.1 & (abs(log2FoldChange)>1)) # FDR<0.1 AND the absolute value of the fold change is >1
print(paste("There are", nrow(filt.results.deseq), "significantly different SVs"))
Nice.Table(filt.results.deseq) #display features in a table
```

Now this is good, but remember our study design is over time, so you must account for this. See [here](https://support.bioconductor.org/p/84241/) for ideas on how to accomplish this.

```{r}
dds = phyloseq_to_deseq2(phyobj, ~ anonymized_name + Timepoint)
geoMeans = apply(counts(dds), 1, gm_mean)
dds = estimateSizeFactors(dds, geoMeans = geoMeans)
dds = DESeq(dds, test="Wald", fitType="local", parallel = TRUE) #may need to set parallel = FALSE on some windows systems
```

Again apply your filtering criteria again and look how this affected our number of significant results. Try changing your significance and fold change cut offs and see how it changes your number of significant features.

```{r}
results.deseq<-as.data.frame(results(dds))
filt.results.deseq<-subset(results.deseq, padj<0.1 & (log2FoldChange>1 | log2FoldChange<(-1)))
print(paste("There are", nrow(filt.results.deseq), "significantly different SVs"))
Nice.Table(filt.results.deseq)
```

Here we have our results, but the actual sequence isn't very helpful. We could look them up in our taxonomy table to find their higher order taxonomic assignments, but instead lets directly try to assign them to a species. Dada2 has a tool for this!

```{r}
#we will only assign species to the sequences in the significant results
species<-assignSpecies(taxonomy[rownames(filt.results.deseq),]$Seq, "rdp_species_assignment_14.fa.gz", allowMultiple = TRUE, verbose=TRUE)
species.results<-cbind(filt.results.deseq, species) #paste the new genus and species names onto the right of the deseq results
Nice.Table(species.results)
```

This is a lot more helpful. <i>*Note that you have the option to allow multiple best hits to species assignments which creates a /-separated list of species. We can now see exactly which organisms have been changed.</i>


It would be nice to help visualize these changes. One common way is a volcano plot. Try to create one with fold change on x, and -log(pvalue) on the y.

```{r}
results.deseq %>%
  left_join(species.results) %>% #add in the names of the significant species
  mutate(Significant=if_else(padj<0.1 & abs(log2FoldChange)>1, "Significant","Not Significant")) %>% #create a new category for if the result is signifcant or not
  ggplot(aes(x=log2FoldChange, y=-log10(pvalue), color=Significant, label=Genus)) +
  geom_point(alpha=0.5) + #alpha here is the opacity which helps visualize overlapping points 
  theme_bw() +
  scale_color_manual(values=c("grey50","red")) + #manually set the colors
  geom_text(hjust=0, vjust=1, alpha=0.5) + #hjust and vjust change the horizontal and vertical alignment +
  ggtitle("Volcano plot of differential features")
      
```

It is also generally a good idea to plot individually. This makes for a good supplemental figure or just as a general sanity check. Lets try this. There are many options for how to plot abundance. In this case I will opt for centered log2 ratio as it is easily it is already on a log scale and interpretting the fold change is easy as every 1 on the y axis corresponds to a 2-fold difference, but try it with multiple methods of plotting including % abundance.

```{r}
Make.CLR(sv.table.analysis) %>% #normalize with CLR
  as.data.frame() %>% #this is a quirk of needing a specific type of table for the functions from the tidyverse package
  rownames_to_column("SV") %>%
  gather(-SV, key="sample_name", value="CLRabundance") %>%
  left_join(metadata) %>%
  filter(SV %in% rownames(filt.results.deseq)) %>% #only keep the significant results from above
  ggplot(aes(x=Timepoint, y=CLRabundance, group=anonymized_name)) +
  geom_line() +
  geom_point() +
  theme_bw() +
  facet_wrap(~SV, scales="free")

```


Why do you think we have a highly abundant organisms with out a known genus or species? How do you think you could fix this problem? Give it a stab and see if you can figure out what SV_2 is. The entire internet is as your fingers and you can find the sequence in your taxonomy table.

### Conclusions:

What do you think this says about organisms that shift during pregnancy? Does this fit with what you saw in your bar plot, alpha diversity and beta diversity analysis? Have you replicated the findings of the original paper? Did you do a more comprehensive analysis than the original paper? How would you analyze the full time series of data instead of just the first and birth visits?

***

# 9. Wrap up {#wrap}

***

You have now completed a fairly comprehensive analysis of a microbiome data set. You started with raw data like you would get direct from a sequencer or read repository. These steps are fairly generalizable to multiple study types. If you think 16S rRNA gene analysis is something you will do often, you should experiment with other approaches and see if you converge on the same conclusions: [QIIME](http://qiime.org), [QIIME2](http://qiime2.org), [UPARSE](http://www.drive5.com/usearch/manual/uparse_pipeline.html), [Mothur](http://mothur.org).
<br><br>
If you would like feedback on your code, please email to [jordan.bisanz@ucsf.edu](mailto:jordan.bisanz@ucsf.edu).
>>>>>>> Stashed changes
